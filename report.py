#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Rapport rapide des r√©sultats - Affichage terminal
Usage: python report.py
"""

import pandas as pd
import glob
from pathlib import Path

# Couleurs ANSI pour le terminal
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'

def print_header(text):
    """Affiche un en-t√™te color√©"""
    print(f"\n{Colors.BOLD}{Colors.CYAN}{'=' * 80}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.CYAN}{text.center(80)}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.CYAN}{'=' * 80}{Colors.END}\n")

def print_section(text):
    """Affiche un titre de section"""
    print(f"\n{Colors.BOLD}{Colors.BLUE}‚ñ∂ {text}{Colors.END}")
    print(f"{Colors.BLUE}{'-' * 80}{Colors.END}")

def print_metric(label, value, unit="", color=Colors.GREEN):
    """Affiche une m√©trique format√©e"""
    print(f"  {Colors.BOLD}{label:<40}{color}{value:>15}{unit}{Colors.END}")

def print_success(text):
    """Affiche un message de succ√®s"""
    print(f"{Colors.GREEN}‚úì {text}{Colors.END}")

def print_warning(text):
    """Affiche un avertissement"""
    print(f"{Colors.YELLOW}‚ö† {text}{Colors.END}")

def print_error(text):
    """Affiche une erreur"""
    print(f"{Colors.RED}‚úó {text}{Colors.END}")

def load_csv(pattern):
    """Charge un CSV Spark avec gestion d'erreur"""
    try:
        files = glob.glob(pattern)
        if not files:
            return None
        return pd.read_csv(files[0], sep=';')
    except Exception as e:
        return None

# ============================================================================
# CHARGEMENT DES DONN√âES
# ============================================================================

print_header("RAPPORT D'ANALYSE - ACCIDENTS ROUTIERS 2023")

print_section("1. Chargement des r√©sultats")

metrics = load_csv("data/metrics.csv/part-*.csv")
predictions_rf = load_csv("data/predictions/randomforest_predictions.csv/part-*.csv")
viz_data = load_csv("data/prepared_for_viz.csv/part-*.csv")

if metrics is not None:
    print_success(f"M√©triques charg√©es ({len(metrics)} mod√®les)")
else:
    print_error("M√©triques non trouv√©es")

if predictions_rf is not None:
    print_success(f"Pr√©dictions charg√©es ({len(predictions_rf)} lignes)")
else:
    print_warning("Pr√©dictions non trouv√©es")

if viz_data is not None:
    print_success(f"Donn√©es de visualisation charg√©es ({len(viz_data)} accidents)")
else:
    print_warning("Donn√©es de visualisation non trouv√©es")

# ============================================================================
# M√âTRIQUES DES MOD√àLES
# ============================================================================

if metrics is not None:
    print_section("2. Performance des Mod√®les ML")
    
    print(f"\n{Colors.BOLD}{'Mod√®le':<25} {'Accuracy':>10} {'Precision':>10} {'Recall':>10} {'F1-Score':>10} {'AUC':>10}{Colors.END}")
    print(f"{Colors.BLUE}{'-' * 80}{Colors.END}")
    
    for _, row in metrics.sort_values('accuracy', ascending=False).iterrows():
        # Couleur bas√©e sur l'accuracy
        if row['accuracy'] > 0.76:
            color = Colors.GREEN
        elif row['accuracy'] > 0.74:
            color = Colors.YELLOW
        else:
            color = Colors.RED
        
        print(f"{color}{row['model']:<25} "
              f"{row['accuracy']:>10.4f} "
              f"{row['precision']:>10.4f} "
              f"{row['recall']:>10.4f} "
              f"{row['f1']:>10.4f} "
              f"{row['auc']:>10.4f}{Colors.END}")
    
    # Meilleur mod√®le
    best_model = metrics.loc[metrics['accuracy'].idxmax()]
    print(f"\n{Colors.BOLD}{Colors.GREEN}üèÜ Meilleur mod√®le: {best_model['model']} "
          f"(Accuracy: {best_model['accuracy']:.2%}){Colors.END}")

# ============================================================================
# STATISTIQUES DES PR√âDICTIONS
# ============================================================================

if predictions_rf is not None:
    print_section("3. Statistiques des Pr√©dictions (Random Forest)")
    
    # Calculer les statistiques
    total = len(predictions_rf)
    correct = len(predictions_rf[predictions_rf['label'] == predictions_rf['prediction']])
    incorrect = total - correct
    
    graves_reels = len(predictions_rf[predictions_rf['label'] == 1])
    graves_predits = len(predictions_rf[predictions_rf['prediction'] == 1])
    
    # Matrice de confusion
    tp = len(predictions_rf[(predictions_rf['label'] == 1) & (predictions_rf['prediction'] == 1)])
    tn = len(predictions_rf[(predictions_rf['label'] == 0) & (predictions_rf['prediction'] == 0)])
    fp = len(predictions_rf[(predictions_rf['label'] == 0) & (predictions_rf['prediction'] == 1)])
    fn = len(predictions_rf[(predictions_rf['label'] == 1) & (predictions_rf['prediction'] == 0)])
    
    print_metric("Total de pr√©dictions", f"{total:,}")
    print_metric("Pr√©dictions correctes", f"{correct:,}", f" ({correct/total:.1%})", Colors.GREEN)
    print_metric("Pr√©dictions incorrectes", f"{incorrect:,}", f" ({incorrect/total:.1%})", Colors.RED)
    
    print(f"\n  {Colors.BOLD}Matrice de confusion:{Colors.END}")
    print(f"    True Positives (TP):  {tp:>6,} {Colors.GREEN}‚úì{Colors.END}")
    print(f"    True Negatives (TN):  {tn:>6,} {Colors.GREEN}‚úì{Colors.END}")
    print(f"    False Positives (FP): {fp:>6,} {Colors.YELLOW}‚ö†{Colors.END}")
    print(f"    False Negatives (FN): {fn:>6,} {Colors.RED}‚úó{Colors.END}")

# ============================================================================
# STATISTIQUES GLOBALES
# ============================================================================

if viz_data is not None:
    print_section("4. Statistiques Globales des Accidents")
    
    total_accidents = len(viz_data)
    accidents_graves = len(viz_data[viz_data['accident_grave'] == 1])
    taux_gravite = (accidents_graves / total_accidents) * 100
    
    print_metric("Total d'accidents analys√©s", f"{total_accidents:,}")
    print_metric("Accidents graves", f"{accidents_graves:,}", f" ({taux_gravite:.1f}%)", Colors.RED)
    print_metric("Accidents non graves", f"{total_accidents - accidents_graves:,}", 
                 f" ({100-taux_gravite:.1f}%)", Colors.GREEN)
    
    # Statistiques par d√©partement (top 5)
    if 'dep' in viz_data.columns:
        print(f"\n  {Colors.BOLD}Top 5 d√©partements (nombre d'accidents):{Colors.END}")
        top_deps = viz_data['dep'].value_counts().head(5)
        for i, (dep, count) in enumerate(top_deps.items(), 1):
            print(f"    {i}. D√©partement {dep}: {count:>6,} accidents")

# ============================================================================
# INSIGHTS CL√âS
# ============================================================================

print_section("5. Insights Cl√©s")

insights = [
    ("üå´Ô∏è Brouillard/Fum√©e", "Risque x1.7", "47.89% de gravit√© (vs 28.37% normal)"),
    ("‚ùÑÔ∏è Neige", "Risque x1.6", "45.71% de gravit√©"),
    ("üåÜ Cr√©puscule", "Risque x1.4", "40.64% de gravit√©"),
    ("üèòÔ∏è Hors agglom√©ration", "Risque x1.8", "40.58% vs 22.05% en agglo"),
    ("üåô Nuit", "Risque +24%", "33.11% vs 26.67% en journ√©e"),
    ("üöõ Poids lourd pr√©sent", "Risque +30%", "36.11% vs 27.77% sans PL"),
    ("üìÖ Weekend", "Risque +21%", "32.27% vs 26.67% en semaine"),
    ("üöó 1 seul v√©hicule", "Risque x1.6", "38.10% vs 23.70% pour 2 v√©hicules"),
]

for emoji, titre, detail in insights:
    print(f"  {Colors.BOLD}{emoji} {titre:<30}{Colors.END} {Colors.YELLOW}{detail}{Colors.END}")

# ============================================================================
# RECOMMANDATIONS
# ============================================================================

print_section("6. Recommandations")

recommendations = [
    "Renforcer la pr√©vention lors de conditions m√©t√©o difficiles (brouillard, neige)",
    "Surveillance accrue hors agglom√©ration (40.6% de gravit√© vs 22% en ville)",
    "Campagnes cibl√©es pour les p√©riodes nocturnes et week-ends",
    "Attention particuli√®re aux accidents impliquant des poids lourds",
    "Mod√®le Random Forest d√©ployable pour pr√©diction en temps r√©el (76.5% accuracy)",
]

for i, rec in enumerate(recommendations, 1):
    print(f"  {Colors.GREEN}{i}.{Colors.END} {rec}")

# ============================================================================
# FICHIERS G√âN√âR√âS
# ============================================================================

print_section("7. Fichiers Disponibles")

files_to_check = [
    ("data/cleaned_data.csv/", "Donn√©es nettoy√©es"),
    ("data/prepared_for_viz.csv/", "Donn√©es pour visualisation"),
    ("data/metrics.csv/", "M√©triques des mod√®les"),
    ("data/predictions/randomforest_predictions.csv/", "Pr√©dictions Random Forest"),
    ("data/predictions/logisticregression_predictions.csv/", "Pr√©dictions R√©gression Logistique"),
    ("data/predictions/decisiontree_predictions.csv/", "Pr√©dictions Arbre de D√©cision"),
    ("data/visualizations/01_synthese_dashboard.html", "Dashboard de synth√®se"),
    ("data/visualizations/02_comparaison_modeles.html", "Comparaison des mod√®les"),
]

for filepath, description in files_to_check:
    if Path(filepath).exists():
        print_success(f"{description:<50} {filepath}")
    else:
        print_warning(f"{description:<50} {filepath} (non trouv√©)")

# ============================================================================
# FOOTER
# ============================================================================

print_header("FIN DU RAPPORT")

print(f"{Colors.BOLD}Pour explorer les visualisations interactives:{Colors.END}")
print(f"  {Colors.CYAN}open data/visualizations/*.html{Colors.END}")
print()
print(f"{Colors.BOLD}Pour consulter les pr√©dictions d√©taill√©es:{Colors.END}")
print(f"  {Colors.CYAN}cat data/predictions/randomforest_predictions.csv/part-*.csv | head{Colors.END}")
print()